{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"name":"get_wordnet_trainset.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"59ebe4ea577c4019813d1ddeb66ea68b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_b6f57fd2863c4036bf6ff5e2a815f96b","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_49b3fd6765a24d8d9ad198eaaa344bb0","IPY_MODEL_58b4f6aa64364fb2942b1036b87ba76c"]}},"b6f57fd2863c4036bf6ff5e2a815f96b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"49b3fd6765a24d8d9ad198eaaa344bb0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_3131d41d8ac34a6cae1cb9daebbbcb78","_dom_classes":[],"description":"Computing transition probabilities: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":29296,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":29296,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8a62b8ddeafb49a2aca39047e996220c"}},"58b4f6aa64364fb2942b1036b87ba76c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a143f2f5aafa49f291f0d20004a5eea4","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 29296/29296 [00:04&lt;00:00, 6648.24it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_84e3410ae39a4477bcd739d5f15dbb11"}},"3131d41d8ac34a6cae1cb9daebbbcb78":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"8a62b8ddeafb49a2aca39047e996220c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a143f2f5aafa49f291f0d20004a5eea4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"84e3410ae39a4477bcd739d5f15dbb11":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"85f037c75c074a71bcdb219e0887d1c8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_c466363062c64e8db7c75f342ac5ba9a","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_7f2f5e693b404df4b25da81bd4db1900","IPY_MODEL_d0ff44cb635e4db58d2e74658528946c"]}},"c466363062c64e8db7c75f342ac5ba9a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7f2f5e693b404df4b25da81bd4db1900":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_c9343e7e3f2240c1819cb80205c71497","_dom_classes":[],"description":"  0%","_model_name":"FloatProgressModel","bar_style":"danger","max":29296,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":0,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6ec467dce3744e5fb1211358dda9c058"}},"d0ff44cb635e4db58d2e74658528946c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_04f9c1c6feac4bee86d25acdbe9d5fd4","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 0/29296 [00:00&lt;?, ?it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9d642438e9e44c2d803149b4cdf05789"}},"c9343e7e3f2240c1819cb80205c71497":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"6ec467dce3744e5fb1211358dda9c058":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"04f9c1c6feac4bee86d25acdbe9d5fd4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"9d642438e9e44c2d803149b4cdf05789":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"48naohLILT5o","executionInfo":{"status":"ok","timestamp":1608310700406,"user_tz":-180,"elapsed":820,"user":{"displayName":"Anton Dmitriev","photoUrl":"","userId":"01520768071657317790"}}},"source":["import json\n","from nltk import wordpunct_tokenize\n","from bs4 import BeautifulSoup as Soup\n","import networkx as nx\n","from collections import defaultdict\n","import copy\n","import numpy as np\n","import torch"],"execution_count":52,"outputs":[]},{"cell_type":"code","metadata":{"id":"LPqoBpTizFPi"},"source":["!pip3 install gensim\n","!pip3 install node2vec"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LXgQz5EXMEe7","executionInfo":{"status":"ok","timestamp":1608310701115,"user_tz":-180,"elapsed":1492,"user":{"displayName":"Anton Dmitriev","photoUrl":"","userId":"01520768071657317790"}},"outputId":"559c3f89-8465-42e7-9fbb-9fb09e7076d9"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":53,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Pd3GAkqBLT5x"},"source":["def parse_synset(file, all_synsets=None):\n","    handler = open(file).read()\n","    soup = Soup(handler)\n","    if all_synsets is None:\n","        all_synsets = {}\n","    for element in soup.findAll('synset'):\n","        all_synsets[element.attrs['id']] = {'name': element.attrs['ruthes_name'], 'definition': element.attrs['definition']}\n","    return all_synsets"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EkAu-CBxLT5y"},"source":["def parse_senses(file):\n","    handler = open(file).read()\n","    soup = Soup(handler)\n","    all_senses = defaultdict(list)\n","    for element in soup.findAll('sense'):\n","        all_senses[element.attrs['synset_id']].append(element.attrs['name'])\n","    return all_senses"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bWsR3qUQLT5y"},"source":["def parse_wordnet(file, synsets, senses=None, G=None, directed=False):\n","    if G is None:\n","        if directed:\n","            G = nx.DiGraph()\n","        else:\n","            G = nx.Graph()\n","    if directed and type(G) != nx.classes.digraph.DiGraph:\n","        raise Exception('Graph is not directed')\n","    if not directed and type(G) != nx.classes.digraph.Graph:\n","        raise Exception('Graph should not be directed')\n","    \n","    print('Input graph: {} nodes, {} edges'.format(len(G.nodes), len(G.edges)))\n","    handler = open(file).read()\n","    soup = Soup(handler)\n","    for element in soup.findAll('relation'):\n","        relation = element.attrs\n","        parent_id = relation['parent_id']\n","        child_id = relation['child_id']\n","        if relation['name'] in ['hyponym', 'instance hyponym']:\n","            if parent_id not in G.nodes:\n","                G.add_node(parent_id, in_edges=[], out_edges=[])\n","            if child_id not in G.nodes:\n","                G.add_node(child_id, in_edges=[], out_edges=[])\n","            parent = G.nodes[parent_id]\n","            child = G.nodes[child_id]\n","            G.add_edge(parent_id, child_id)\n","            if senses is not None:\n","                parent_txt = copy.deepcopy(senses[parent_id])\n","                child_txt = copy.deepcopy(senses[child_id])\n","            else:\n","                parent_txt = [synsets[parent_id]['name']]\n","                child_txt = [synsets[child_id]['name']]\n","            new_attr = {parent_id: {'out_edges': parent['out_edges'] + [child_id], 'text': parent_txt, 'definition': synsets[parent_id]['definition']},\n","                        child_id: {'in_edges': child['in_edges'] + [parent_id], 'text': child_txt, 'definition': synsets[child_id]['definition']}}\n","            nx.set_node_attributes(G, new_attr)\n","    print('Updated graph: {} nodes, {} edges'.format(len(G.nodes), len(G.edges)))\n","    for syn in synsets:\n","        if syn not in G.nodes:\n","            G.add_node(syn)\n","            txt = senses[syn]\n","            defn = synsets[syn]['definition']\n","            nx.set_node_attributes(G, {syn: {'out_edges': [], 'in_edges': [], 'text': txt, 'definition': defn}})\n","    print('Graph with orphan nodes: {} nodes, {} edges'.format(len(G.nodes), len(G.edges)))\n","    return G"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZsnVkUWNMNyc"},"source":["data_dir = '/content/drive/MyDrive/Study/NLP/ruwordnet/'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ghnRrtcmLT50"},"source":["all_senses_noun = parse_senses(data_dir + 'ruwordnet/senses.N.xml')\n","all_senses_verb = parse_senses(data_dir + 'ruwordnet/senses.V.xml')\n","all_synsets_noun = parse_synset(data_dir + 'ruwordnet/synsets.N.xml')\n","all_synsets_verb = parse_synset(data_dir + 'ruwordnet/synsets.V.xml')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-iIMHPGHLT53","executionInfo":{"status":"ok","timestamp":1608250462814,"user_tz":-180,"elapsed":23206,"user":{"displayName":"Anton Dmitriev","photoUrl":"","userId":"01520768071657317790"}},"outputId":"c665659f-29bd-4c7c-b96e-0e7ccdccd436"},"source":["# wordnet graphs - directed\n","G_full_dir_noun = parse_wordnet(data_dir + 'ruwordnet/synset_relations.N.xml', all_synsets_noun, all_senses_noun, directed=True)\n","G_full_dir_verb = parse_wordnet(data_dir + 'ruwordnet/synset_relations.V.xml', all_synsets_verb, all_senses_verb, directed=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Input graph: 0 nodes, 0 edges\n","Updated graph: 29295 nodes, 39110 edges\n","Graph with orphan nodes: 29296 nodes, 39110 edges\n","Input graph: 0 nodes, 0 edges\n","Updated graph: 7408 nodes, 10317 edges\n","Graph with orphan nodes: 7521 nodes, 10317 edges\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wNYnLODdLT54"},"source":["# My fitting code"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":67,"referenced_widgets":["59ebe4ea577c4019813d1ddeb66ea68b","b6f57fd2863c4036bf6ff5e2a815f96b","49b3fd6765a24d8d9ad198eaaa344bb0","58b4f6aa64364fb2942b1036b87ba76c","3131d41d8ac34a6cae1cb9daebbbcb78","8a62b8ddeafb49a2aca39047e996220c","a143f2f5aafa49f291f0d20004a5eea4","84e3410ae39a4477bcd739d5f15dbb11"]},"id":"wHTyyRjULT55","executionInfo":{"status":"ok","timestamp":1608253877416,"user_tz":-180,"elapsed":3316824,"user":{"displayName":"Anton Dmitriev","photoUrl":"","userId":"01520768071657317790"}},"outputId":"aaa009ee-3eef-4669-ba09-26d5adbc836c"},"source":["from node2vec.node2vec import Node2Vec\n","EMBEDDING_FILENAME = './embeddings.emb'\n","EMBEDDING_MODEL_FILENAME = './embeddings.model'\n","\n","node2vec = Node2Vec(G_full_dir_noun, dimensions=100, walk_length=30, num_walks=200, workers=4)\n","model = node2vec.fit(window=20, min_count=1, batch_words=4)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"59ebe4ea577c4019813d1ddeb66ea68b","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Computing transition probabilities', max=29296.0, style=P…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"79_GGsisLT59"},"source":["import gensim\n","ft_model = gensim.models.KeyedVectors.load('/content/drive/MyDrive/Study/NLP/models/araneum_none_fasttextcbow_300_5_2018.model')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wq2eskroLT56","executionInfo":{"status":"ok","timestamp":1608253877418,"user_tz":-180,"elapsed":3310943,"user":{"displayName":"Anton Dmitriev","photoUrl":"","userId":"01520768071657317790"}},"outputId":"56cc8af1-0217-47d6-ea2b-6c22e5bdc523"},"source":["len(G_full_dir_noun.nodes)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["29296"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Sq0JtequLT58","executionInfo":{"status":"ok","timestamp":1608253877419,"user_tz":-180,"elapsed":3310460,"user":{"displayName":"Anton Dmitriev","photoUrl":"","userId":"01520768071657317790"}},"outputId":"b4c906ba-20cf-4c72-98ea-7ade22a1dc27"},"source":["len(all_senses_noun)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["29296"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"markdown","metadata":{"id":"598mk6x2LT58"},"source":["And then we can get word by id from the database and do whatever we want"]},{"cell_type":"code","metadata":{"id":"HoASnBJqLT58"},"source":["def build_id_to_noun_map(all_sences):\n","    result = {}\n","    for key, value_arr in all_sences.items():\n","        for v in calue_arr:\n","            result[v] = key\n","    return result"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dtyfDCIVLT59"},"source":["from tqdm.notebook import tqdm\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":487,"referenced_widgets":["85f037c75c074a71bcdb219e0887d1c8","c466363062c64e8db7c75f342ac5ba9a","7f2f5e693b404df4b25da81bd4db1900","d0ff44cb635e4db58d2e74658528946c","c9343e7e3f2240c1819cb80205c71497","6ec467dce3744e5fb1211358dda9c058","04f9c1c6feac4bee86d25acdbe9d5fd4","9d642438e9e44c2d803149b4cdf05789"]},"id":"H177tYzBLT5-","executionInfo":{"status":"error","timestamp":1608254041742,"user_tz":-180,"elapsed":23287,"user":{"displayName":"Anton Dmitriev","photoUrl":"","userId":"01520768071657317790"}},"outputId":"e2779279-b4aa-42f0-b8f6-6c406fc44aca"},"source":["train_from = []\n","train_to = []\n","\n","def get_ft_embedding(ft_model, word):\n","    emb = 0\n","    i = 0\n","    for w in word.lower().split(' '):\n","        emb += ft_model.wv[w]\n","        i += 1\n","    return emb / i\n","\n","for ident in tqdm(G_full_dir_noun.nodes):\n","    words = all_senses_noun[ident]\n","    n2v_vec = model.wv[ident]\n","    for w in words:\n","        ft_vec = get_ft_embedding(ft_model, w)\n","        train_from.append(ft_vec)\n","        train_to.append(n2v_vec)\n","        \n","train_from = np.vstack(train_from)\n","train_to = np.vstack(train_to)\n","\n","print(train_from.shape)\n","print(train_to.shape)\n","\n","np.save('../train_from.npy', train_from)\n","np.save('../train_to.npy', train_to)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"85f037c75c074a71bcdb219e0887d1c8","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=29296.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n","  \n"],"name":"stderr"},{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-e1755c30b251>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mn2v_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mident\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mft_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_ft_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mft_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mtrain_from\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mft_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mtrain_to\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn2v_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-22-e1755c30b251>\u001b[0m in \u001b[0;36mget_ft_embedding\u001b[0;34m(ft_model, word)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0memb\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mft_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0memb\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, entities)\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0;31m# allow calls like trained_model['office'], as a shorthand for trained_model[['office']]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentity\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentity\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentities\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_vector\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwords_closer_than\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[0;34m(self, word, use_norm)\u001b[0m\n\u001b[1;32m   1983\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mngram\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mngrams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1984\u001b[0m                 \u001b[0mngram_hash\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ft_hash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngram\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbucket\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1985\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mngram_hash\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhash2index\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1986\u001b[0m                     \u001b[0mword_vec\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mngram_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhash2index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mngram_hash\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1987\u001b[0m                     \u001b[0mngrams_found\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'FastTextKeyedVectors' object has no attribute 'hash2index'"]}]},{"cell_type":"code","metadata":{"id":"wKDYcx-ILT5_","executionInfo":{"status":"ok","timestamp":1608310994927,"user_tz":-180,"elapsed":4039,"user":{"displayName":"Anton Dmitriev","photoUrl":"","userId":"01520768071657317790"}}},"source":["import numpy as np\n","train_from = np.load('/content/drive/MyDrive/Study/NLP/train_data/train_from.npy')\n","train_to = np.load('/content/drive/MyDrive/Study/NLP/train_data/train_to.npy')"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"WgVoMP3hbARc"},"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"orkzwBm3LT5_"},"source":["indexes = np.arange(len(train_from))\n","np.random.shuffle(indexes)\n","\n","train_source = train_from[indexes[:-5000]]\n","train_target = train_to[indexes[:-5000]]\n","test_source = train_from[indexes[-5000:]]\n","test_target = train_to[indexes[-5000:]]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"z-sDEpTKNCRR"},"source":["# Baseline"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RbA6SyHpaj5_","executionInfo":{"status":"ok","timestamp":1608301006581,"user_tz":-180,"elapsed":721,"user":{"displayName":"Anton Dmitriev","photoUrl":"","userId":"01520768071657317790"}},"outputId":"91caf2eb-354c-48b6-ca9a-8a9111862a80"},"source":["import torch\n","\n","torch.cuda.is_available()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["False"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"vDeeYSgVNB64"},"source":["import torch\n","import torch.nn as nn\n","\n","enc_dec_model = nn.Sequential(\n","    nn.Linear(300, 300)\n",").to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-agfIcsbNVNQ"},"source":["EPOCHS = 200\n","batch_size = 500\n","lr = 0.01\n","\n","optimizer = torch.optim.Adam(enc_dec_model.parameters(), lr=lr)\n","criterion = torch.nn.MSELoss()\n","\n","cos = torch.nn.CosineSimilarity()\n","def loss_func(outputs, true):\n","    return (1 - cos(outputs, true)).mean()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TPm2Dh_KNXOO"},"source":["def cross_cosine_similarity(vec_batch_1, vec_batch_2):\n","    vec_batch_1 = vec_batch_1 / torch.norm(vec_batch_1, dim=-1, keepdim=True)\n","    vec_batch_2 = vec_batch_2 / torch.norm(vec_batch_2, dim=-1, keepdim=True)\n","    return torch.mm(vec_batch_1, vec_batch_2.T)    \n","\n","def evaluate_ranking_score(true_test_vectors, predicted_vectors, N, soft=False):\n","    cos_sim = cross_cosine_similarity(predicted_vectors, true_test_vectors)\n","    indexes = torch.argsort(cos_sim, axis=1, descending=True)\n","    true = torch.from_numpy(np.arange(len(indexes))).type(torch.IntTensor).T.to(device)\n","    positions = (indexes == true.reshape(-1, 1)).nonzero()[:, 1].type(torch.FloatTensor).to(device)\n","    score = torch.zeros(len(indexes)).type(torch.FloatTensor).to(device)\n","    if not soft:\n","        score[positions < N] = 1 / (positions[positions < N] + 1)\n","    else:\n","        score[positions < N] = 1\n","    return score.mean()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4_ncX-E6NYDl"},"source":["import time\n","\n","num_batch = len(train_source) // batch_size if len(train_source) % batch_size == 0 else len(train_source) // batch_size + 1\n","num_batch_test = len(test_source) // batch_size if len(test_source) % batch_size == 0 else len(test_source) // batch_size + 1\n","\n","for epoch in range(EPOCHS):\n","    t = time.time()\n","    train_loss = 0\n","    for b in range(num_batch):\n","        optimizer.zero_grad()\n","        source = torch.from_numpy(train_source[b*batch_size:(b+1)*batch_size]).to(device)\n","        target = torch.from_numpy(train_target[b*batch_size:(b+1)*batch_size]).to(device)\n","        outputs = enc_dec_model(source)\n","        loss = loss_func(outputs, target)\n","        loss.backward()\n","        optimizer.step()\n","        train_loss += loss.detach().cpu().numpy()\n","    train_loss = train_loss / num_batch\n","    \n","    with torch.no_grad():\n","        test_loss = 0\n","        rank_score_1 = 0\n","        rank_score_5 = 0\n","        rank_score_10 = 0\n","        soft_rank_score_1 = 0\n","        soft_rank_score_5 = 0\n","        soft_rank_score_10 = 0\n","        for b in range(num_batch_test):\n","            source = torch.from_numpy(test_source[b*batch_size:(b+1)*batch_size]).to(device)\n","            target = torch.from_numpy(test_target[b*batch_size:(b+1)*batch_size]).to(device)\n","            outputs = enc_dec_model(source)\n","            loss = loss_func(outputs, target)\n","            \n","            test_loss += loss.detach().cpu().numpy()\n","\n","            rank_score_1 += evaluate_ranking_score(target, outputs, 1)\n","            rank_score_5 += evaluate_ranking_score(target, outputs, 5)\n","            rank_score_10 += evaluate_ranking_score(target, outputs, 10)\n","\n","            soft_rank_score_1 += evaluate_ranking_score(target, outputs, 1, True)\n","            soft_rank_score_5 += evaluate_ranking_score(target, outputs, 5, True)\n","            soft_rank_score_10 += evaluate_ranking_score(target, outputs, 10, True)\n","            \n","        test_loss = test_loss / num_batch_test\n","        rank_score_1 /= num_batch_test\n","        rank_score_5 /= num_batch_test\n","        rank_score_10 /= num_batch_test\n","        soft_rank_score_1 /= num_batch_test\n","        soft_rank_score_5 /= num_batch_test\n","        soft_rank_score_10 /= num_batch_test\n","        \n","        print(f'Epoch {epoch} \\t Mean train loss {train_loss} \\t Mean test loss {test_loss} \\t Time {time.time() - t}')\n","        print(f'Rank score 1 {rank_score_1} \\t Rank_score 5 {rank_score_5} \\t Rank score 10 {rank_score_10}')\n","        print(f'Soft rank score 1 {soft_rank_score_1} \\t Soft rank_score 5 {soft_rank_score_5} \\t Soft rank score 10 {soft_rank_score_10}')\n","        print('------------------------------------------------------------------------------------------------------------')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"igExhMCXNEX6"},"source":["# Model 2"]},{"cell_type":"code","metadata":{"id":"V0exNUecLT5_"},"source":["import torch\n","import torch.nn as nn\n","\n","enc_dec_model = nn.Sequential(\n","    nn.Linear(300, 400),\n","    nn.ReLU(),\n","    nn.Linear(400, 500),\n","    nn.ReLU(),\n","    nn.Linear(500, 500),\n","    nn.ReLU(),\n","    nn.Linear(500, 500),\n","    nn.ReLU(),\n","    nn.Linear(500, 500),\n","    nn.ReLU(),\n","    nn.Linear(500, 400),\n","    nn.ReLU(),\n","    nn.Linear(400, 300)\n",").to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DCn2hZIqLT5_"},"source":["EPOCHS = 200\n","batch_size = 500\n","lr = 0.01\n","\n","optimizer = torch.optim.Adam(enc_dec_model.parameters(), lr=lr)\n","criterion = torch.nn.MSELoss()\n","\n","cos = torch.nn.CosineSimilarity()\n","def loss_func(outputs, true):\n","    return (1 - cos(outputs, true)).mean()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_bXBB-juLT6A"},"source":["def cross_cosine_similarity(vec_batch_1, vec_batch_2):\n","    vec_batch_1 = vec_batch_1 / torch.norm(vec_batch_1, dim=-1, keepdim=True)\n","    vec_batch_2 = vec_batch_2 / torch.norm(vec_batch_2, dim=-1, keepdim=True)\n","    return torch.mm(vec_batch_1, vec_batch_2.T)    \n","\n","def evaluate_ranking_score(true_test_vectors, predicted_vectors, N, soft=False):\n","    cos_sim = cross_cosine_similarity(predicted_vectors, true_test_vectors)\n","    indexes = torch.argsort(cos_sim, axis=1, descending=True)\n","    true = torch.from_numpy(np.arange(len(indexes))).type(torch.IntTensor).T.to(device)\n","    positions = (indexes == true.reshape(-1, 1)).nonzero()[:, 1].type(torch.FloatTensor).to(device)\n","    score = torch.zeros(len(indexes)).type(torch.FloatTensor).to(device)\n","    if not soft:\n","        score[positions < N] = 1 / (positions[positions < N] + 1)\n","    else:\n","        score[positions < N] = 1\n","    return score.mean()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s9M9lfmjLT6A"},"source":["import time\n","\n","num_batch = len(train_source) // batch_size if len(train_source) % batch_size == 0 else len(train_source) // batch_size + 1\n","num_batch_test = len(test_source) // batch_size if len(test_source) % batch_size == 0 else len(test_source) // batch_size + 1\n","\n","for epoch in range(EPOCHS):\n","    t = time.time()\n","    train_loss = 0\n","    for b in range(num_batch):\n","        optimizer.zero_grad()\n","        source = torch.from_numpy(train_source[b*batch_size:(b+1)*batch_size]).to(device)\n","        target = torch.from_numpy(train_target[b*batch_size:(b+1)*batch_size]).to(device)\n","        outputs = enc_dec_model(source)\n","        loss = loss_func(outputs, target)\n","        loss.backward()\n","        optimizer.step()\n","        train_loss += loss.detach().cpu().numpy()\n","    train_loss = train_loss / num_batch\n","    \n","    with torch.no_grad():\n","        test_loss = 0\n","        rank_score_1 = 0\n","        rank_score_5 = 0\n","        rank_score_10 = 0\n","        soft_rank_score_1 = 0\n","        soft_rank_score_5 = 0\n","        soft_rank_score_10 = 0\n","        for b in range(num_batch_test):\n","            source = torch.from_numpy(test_source[b*batch_size:(b+1)*batch_size]).to(device)\n","            target = torch.from_numpy(test_target[b*batch_size:(b+1)*batch_size]).to(device)\n","            outputs = enc_dec_model(source)\n","            loss = loss_func(outputs, target)\n","            \n","            test_loss += loss.detach().cpu().numpy()\n","\n","            rank_score_1 += evaluate_ranking_score(target, outputs, 1)\n","            rank_score_5 += evaluate_ranking_score(target, outputs, 5)\n","            rank_score_10 += evaluate_ranking_score(target, outputs, 10)\n","\n","            soft_rank_score_1 += evaluate_ranking_score(target, outputs, 1, True)\n","            soft_rank_score_5 += evaluate_ranking_score(target, outputs, 5, True)\n","            soft_rank_score_10 += evaluate_ranking_score(target, outputs, 10, True)\n","            \n","        test_loss = test_loss / num_batch_test\n","        rank_score_1 /= num_batch_test\n","        rank_score_5 /= num_batch_test\n","        rank_score_10 /= num_batch_test\n","        soft_rank_score_1 /= num_batch_test\n","        soft_rank_score_5 /= num_batch_test\n","        soft_rank_score_10 /= num_batch_test\n","        \n","        print(f'Epoch {epoch} \\t Mean train loss {train_loss} \\t Mean test loss {test_loss} \\t Time {time.time() - t}')\n","        print(f'Rank score 1 {rank_score_1} \\t Rank_score 5 {rank_score_5} \\t Rank score 10 {rank_score_10}')\n","        print(f'Soft rank score 1 {soft_rank_score_1} \\t Soft rank_score 5 {soft_rank_score_5} \\t Soft rank score 10 {soft_rank_score_10}')\n","        print('------------------------------------------------------------------------------------------------------------')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uCcnPKFANI27"},"source":["# Model 3"]},{"cell_type":"code","metadata":{"id":"iTWBfF8JcVDu"},"source":["import torch.nn as nn\n","\n","EPOCHS = 200\n","batch_size = 500\n","lr = 0.01\n","\n","enc_ft_model = nn.Sequential(\n","    nn.Linear(300, 400),\n","    nn.ReLU(),\n","    nn.Linear(400, 500)#,\n","    #nn.ReLU(),\n","    #nn.Linear(500, 500)\n",").to(device)\n","\n","enc_node_model = nn.Sequential(\n","    nn.Linear(300, 400),\n","    nn.ReLU(),\n","    nn.Linear(400, 500)#,\n","    #nn.ReLU(),\n","    #nn.Linear(500, 500)\n",").to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CB0Vmnk4hRdh"},"source":["optimizer = torch.optim.Adam([i for i in enc_ft_model.parameters()] + [i for i in enc_node_model.parameters()], lr=lr)\n","\n","cos = torch.nn.CosineSimilarity()\n","def loss_func(outputs, true, labels):\n","    return ((labels - cos(outputs, true)) ** 2).mean()\n","\n","def cross_cosine_similarity(vec_batch_1, vec_batch_2):\n","    vec_batch_1 = vec_batch_1 / torch.norm(vec_batch_1, dim=-1, keepdim=True)\n","    vec_batch_2 = vec_batch_2 / torch.norm(vec_batch_2, dim=-1, keepdim=True)\n","    return torch.mm(vec_batch_1, vec_batch_2.T)    \n","\n","def evaluate_ranking_score(true_test_vectors, predicted_vectors, N, soft=False):\n","    cos_sim = cross_cosine_similarity(predicted_vectors, true_test_vectors)\n","    indexes = torch.argsort(cos_sim, axis=1, descending=True)\n","    true = torch.from_numpy(np.arange(len(indexes))).type(torch.IntTensor).T.to(device)\n","    positions = (indexes == true.reshape(-1, 1)).nonzero()[:, 1].type(torch.FloatTensor).to(device)\n","    score = torch.zeros(len(indexes)).type(torch.FloatTensor).to(device)\n","    if not soft:\n","        score[positions < N] = 1 / (positions[positions < N] + 1)\n","    else:\n","        score[positions < N] = 1\n","    return score.mean()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YjCZ3J_4onts"},"source":["def generate_batch(source, target, batch_size, positive_part=0.5):\n","    indexes = np.arange(len(source))\n","    pos_ind = np.random.choice(indexes, int(batch_size * positive_part))\n","    p_source = source[pos_ind]\n","    p_target = target[pos_ind]\n","\n","    neg_size = batch_size - int(batch_size * positive_part)\n","    available_neg_inds = np.setdiff1d(indexes, pos_ind)\n","    neg_ind_s = np.random.choice(available_neg_inds, neg_size)\n","    neg_ind_t = np.random.choice(np.setdiff1d(available_neg_inds, neg_ind_s), neg_size)\n","    neg_source = source[neg_ind_s]\n","    neg_target = target[neg_ind_t]\n","\n","    result_source = np.concatenate((p_source, neg_source), axis=0)\n","    result_target = np.concatenate((p_target, neg_target), axis=0)\n","    labels = np.array([1 for i in range(len(p_source))] + [0 for i in range(len(neg_source))])\n","\n","    inds = np.arange(batch_size)\n","    np.random.shuffle(inds)\n","    return result_source[inds], result_target[inds], labels[inds]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gy0D3dV_gqgQ"},"source":["import time\n","\n","num_batch = len(train_source) // batch_size if len(train_source) % batch_size == 0 else len(train_source) // batch_size + 1\n","num_batch_test = len(test_source) // batch_size if len(test_source) % batch_size == 0 else len(test_source) // batch_size + 1\n","\n","for epoch in range(EPOCHS):\n","    t = time.time()\n","    train_loss = 0\n","    for b in range(num_batch):\n","        optimizer.zero_grad()\n","        source, target, labels = generate_batch(train_source, train_target, batch_size)\n","        source = torch.from_numpy(source).to(device)\n","        target = torch.from_numpy(target).to(device)\n","        labels = torch.from_numpy(labels).to(device)\n","        outputs_ft = enc_ft_model(source)\n","        outputs_node = enc_node_model(target)\n","        loss = loss_func(outputs_ft, outputs_node, labels)\n","        loss.backward()\n","        optimizer.step()\n","        train_loss += loss.detach().cpu().numpy()\n","    train_loss = train_loss / num_batch\n","    \n","    with torch.no_grad():\n","        test_loss = 0\n","\n","        rank_score_1 = 0\n","        rank_score_5 = 0\n","        rank_score_10 = 0\n","\n","        soft_rank_score_1 = 0\n","        soft_rank_score_5 = 0\n","        soft_rank_score_10 = 0\n","        for b in range(num_batch_test):\n","            source = torch.from_numpy(test_source[b*batch_size:(b+1)*batch_size]).to(device)\n","            target = torch.from_numpy(test_target[b*batch_size:(b+1)*batch_size]).to(device)\n","            outputs_ft = enc_ft_model(source)\n","            outputs_node = enc_node_model(target)\n","            loss = loss_func(outputs_ft, outputs_node, torch.ones(batch_size).to(device))\n","            \n","            test_loss += loss.detach().cpu().numpy()\n","\n","            rank_score_1 += evaluate_ranking_score(outputs_node, outputs_ft, 1)\n","            rank_score_5 += evaluate_ranking_score(outputs_node, outputs_ft, 5)\n","            rank_score_10 += evaluate_ranking_score(outputs_node, outputs_ft, 10)\n","\n","            soft_rank_score_1 += evaluate_ranking_score(outputs_node, outputs_ft, 1, True)\n","            soft_rank_score_5 += evaluate_ranking_score(outputs_node, outputs_ft, 5, True)\n","            soft_rank_score_10 += evaluate_ranking_score(outputs_node, outputs_ft, 10, True)\n","            \n","        test_loss = test_loss / num_batch_test\n","        rank_score_1 /= num_batch_test\n","        rank_score_5 /= num_batch_test\n","        rank_score_10 /= num_batch_test\n","        soft_rank_score_1 /= num_batch_test\n","        soft_rank_score_5 /= num_batch_test\n","        soft_rank_score_10 /= num_batch_test\n","        \n","        print(f'Epoch {epoch} \\t Mean train loss {train_loss} \\t Mean test loss {test_loss} \\t Time {time.time() - t}')\n","        print(f'Rank score 1 {rank_score_1} \\t Rank_score 5 {rank_score_5} \\t Rank score 10 {rank_score_10}')\n","        print(f'Soft rank score 1 {soft_rank_score_1} \\t Soft rank_score 5 {soft_rank_score_5} \\t Soft rank score 10 {soft_rank_score_10}')\n","        print('------------------------------------------------------------------------------------------------------------')"],"execution_count":null,"outputs":[]}]}